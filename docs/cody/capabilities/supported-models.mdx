# Supported LLMs

## Chat and Prompts

Cody supports a variety of cutting-edge large language models for use in chat and prompts, allowing you to select the best model for your use case.

<Callout type="note">Newer versions of Sourcegraph Enterprise, starting from v5.6, it will be even easier to add support for new models and providers, see [Model Configuration](/cody/enterprise/model-configuration) for more information.</Callout>

| **Provider**  |                                                                   **Model**                                                                   |   **Free**   |   **Pro**    | **Enterprise** |     |     |     |     |
| :------------ | :-------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :----------- | :------------- | --- | --- | --- | --- |
| OpenAI        | [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo#:~:text=TRAINING%20DATA-,gpt%2D4%2D0125%2Dpreview,-New%20GPT%2D4) | -            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [GPT-4o](https://platform.openai.com/docs/models#gpt-4o) | -            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [GPT-4o-mini](https://platform.openai.com/docs/models#gpt-4o-mini) | ✅            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [o3-mini-medium](https://openai.com/index/openai-o3-mini/) (experimental)                                                                                      | ✅            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [o3-mini-high](https://openai.com/index/openai-o3-mini/) (experimental)                                                                                      | -            | -            | ✅              |     |     |     |     |
| OpenAI        | [o3](https://platform.openai.com/docs/models#o3)                                                                                      | -            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [o4-mini](https://platform.openai.com/docs/models/o4-mini)                                                                                      | ✅            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1)                                                                                      | -            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [GPT-4.1-mini](https://platform.openai.com/docs/models/gpt-4o-mini)                                                                                      | ✅            | ✅            | ✅              |     |     |     |     |
| OpenAI        | [GPT-4.1-nano](https://platform.openai.com/docs/models/gpt-4.1-nano)                                                                                      | ✅            | ✅            | ✅              |     |     |     |     |
| Anthropic     | [Claude 3.5 Haiku](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)                                                     | ✅            | ✅            | ✅              |     |     |     |     |
| Anthropic     | [Claude 3.5 Sonnet](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)                                                  | ✅            | ✅            | ✅              |     |     |     |     |
| Anthropic     | [Claude 3.7 Sonnet](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)                                                  | -            | ✅            | ✅              |     |     |     |     |
| Google | [Gemini 1.5 Pro](https://deepmind.google/technologies/gemini/pro/)                                                                                   | ✅            | ✅            | ✅ (beta)       |     |     |     |     |
| Google | [Gemini 2.0 Flash](https://deepmind.google/technologies/gemini/flash/)                                                                               | ✅            | ✅            | ✅       |     |     |     |     |
| Google | [Gemini 2.0 Flash](https://deepmind.google/technologies/gemini/flash/)                                                                               | ✅            | ✅            | ✅       |     |     |     |     |
| Google | [Gemini 2.5 Pro Preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro)                                                                               | -            | ✅            | ✅       |     |     |     |     |
| Google | [Gemini 2.5 Flash Preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash) (experimental)                                                                               | ✅            | ✅            | ✅       |     |     |     |     |

<Callout type="note">To use Claude 3 Sonnet models with Cody Enterprise, make sure you've upgraded your Sourcegraph instance to the latest version. </Callout>

### Claude 3.7 Sonnet

Claude 3.7 has two variants — Claude 3.7 Sonnet and Claude 3.7 Extended Thinking — to support deep reasoning and fast, responsive edit workflows. This means you can use Claude 3.7 in different contexts depending on whether long-form reasoning is required or for tasks where speed and performance are a priority.

Claude 3.7 Extended Thinking is the recommended default chat model for Cloud customers. Self-hosted customers are encouraged to follow this recommendation, as Claude 3.7 outperforms 3.5 in most scenarios.

#### Claude 3.7 for GCP

In addition, Sourcegraph Enterprise customers using GCP Vertex (Google Cloud Platform) for Claude models can use both these variants of Claude 3.7 to optimize extended reasoning and deeper understanding. Customers using AWS Bedrock do not have the Claude 3.7 Extended Thinking variant.

<Callout type="info">Claude 3.7 Sonnet with thinking is not supported for BYOK deployments.</Callout>

#### Claude 3.7 Sonnet and Claude 4 Sonnet for AWS Bedrock

Cody's BYOK AWS Bedrock support can use Claude 3.7 Sonnet's **thinking mode**. Once enabled, Cody routes your prompts through Claude 3.7 Sonnet, using its expanded context window and advanced reasoning abilities to return noticeably smarter, more context-aware responses.

## Autocomplete

Cody uses a set of models for autocomplete which are suited for the low latency use case.

| **Provider** |                                         **Model**                                         | **Free** | **Pro** | **Enterprise** |     |     |     |     |
| :----------- | :---------------------------------------------------------------------------------------- | :------- | :------ | :------------- | --- | --- | --- | --- |
| Fireworks.ai | [DeepSeek-Coder-V2](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)   | ✅        | ✅       | ✅              |     |     |     |     |
| Anthropic    | [claude Instant](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | -        | -       | ✅              |     |     |     |     |
|              |                                                                                           |          |         |                |     |     |     |     |

<Callout type="note">The default autocomplete model for Cody Free, Pro and Enterprise users is DeepSeek-Coder-V2.</Callout>

<Callout type="note">The DeepSeek model used by Sourcegraph is hosted by Fireworks.ai, and is hosted as a single-tenant service in a US-based data center. For more information see our [Cody FAQ](https://sourcegraph.com/docs/cody/faq#is-any-of-my-data-sent-to-deepseek).</Callout>

## Smart Apply

| **Provider** |   **Model**    | **Free** | **Pro** | **Enterprise** |     |     |     |     |     |     |
| :----------- | :------------- | :------- | :------ | :------------- | --- | --- | --- | --- | --- | --- |
| Fireworks.ai | Qwen 2.5 Coder | ✅        | ✅       | ✅              |     |     |     |     |     |     |

<Callout type="note">Enterprise users not using Cody Gateway get a Claude Sonnet-based model for Smart Apply.</Callout>
