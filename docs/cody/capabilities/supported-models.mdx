# Supported Large Language Models

## Chat

Cody supports a variety of cutting edge large language models for use in Chat, allowing you to select the best model for your use case.  Free users are defaulted to Claude 2.0 model from Anthropic, while Pro users have access to select any supported model.

| **Provider** | **Model** | **Free** | **Pro** | **Enterprise** |
|:--|:--|:--|:--|:--|
| OpenAI | [gpt-3.5 turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo) | - | ✅ | - |
| OpenAI | [gpt-4 turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo#:~:text=TRAINING%20DATA-,gpt%2D4%2D0125%2Dpreview,-New%20GPT%2D4) | - | ✅ | - |
| OpenAI | [gpt-4](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) | - | - | ✅ |
| Anthropic| [claude Instant](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | ✅ | - |
| Anthropic| [claude-2.0](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | ✅ | ✅ | ✅ |
| Anthropic| [claude-2.1](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | ✅ | ✅ |
| Anthropic| [claude-3 Haiku](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | ✅ | *coming soon* |
| Anthropic| [claude-3 Sonnet](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | ✅ | *coming soon* |
| Anthropic| [claude-3 Opus](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | ✅ | *coming soon* |
| Mistral| [mixtral 8x7b](https://mistral.ai/technology/#models:~:text=of%20use%20cases.-,Mixtral%208x7B,-Currently%20the%20best) | - | ✅ | - |
| Ollama* | [variety](https://ollama.com/) | *experimental*| *experimental* | - |
||||||

## Autocomplete

Cody uses a set of models for autocomplete which are suited for the low latency use case. 

| **Provider** | **Model** | **Free** | **Pro** | **Enterprise** |
|:--|:--|:--|:--|:--|
| Fireworks.ai | [StarCoder](https://arxiv.org/abs/2305.06161) | ✅ | ✅ | ✅ |
| Anthropic| [claude Instant](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | - | - | ✅ |
| Ollama* | [variety](https://ollama.com/) | *experimental*| *experimental* | - |
||||||



<Callout type="note">[See here for Ollama setup instructions](https://sourcegraph.com/docs/cody/clients/install-vscode#supported-local-ollama-models-with-cody)</Callout>