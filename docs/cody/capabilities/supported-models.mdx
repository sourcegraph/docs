# Supported LLMs

## Chat and Prompts

Cody supports a variety of cutting-edge large language models for use in chat and prompts, allowing you to select the best model for your use case.

<Callout type="note">
	Newer versions of Sourcegraph Enterprise, starting from v5.6, it will be
	even easier to add support for new models and providers, see [Model
	Configuration](/cody/enterprise/model-configuration) for more information.
</Callout>

| **Provider** | **Model**                                                                                                                                     | **Status**        | **Vision Support** |
| :----------- | :-------------------------------------------------------------------------------------------------------------------------------------------- | :---------------- | :----------------- |
| OpenAI       | [GPT-5](https://platform.openai.com/docs/models/gpt-5)                                                                                        | ✅                | ✅                 |
| OpenAI       | [GPT-5.1](https://platform.openai.com/docs/models/gpt-5.1)                                                                                    | ✅                | ✅                 |
| OpenAI       | [GPT-5-mini](https://platform.openai.com/docs/models/gpt-5-mini)                                                                              | ✅                | ✅                 |
| OpenAI       | [GPT-5-nano](https://platform.openai.com/docs/models/gpt-5-nano)                                                                              | ✅                | ✅                 |
| OpenAI       | [GPT-4-Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo#:~:text=TRAINING%20DATA-,gpt%2D4%2D0125%2Dpreview,-New%20GPT%2D4) | ✅                | ❌                 |
| OpenAI       | [GPT-4o](https://platform.openai.com/docs/models#gpt-4o)                                                                                      | ✅                | ✅                 |
| OpenAI       | [GPT-4o-mini](https://platform.openai.com/docs/models#gpt-4o-mini)                                                                            | ✅                | ✅                 |
| OpenAI       | [o3-mini-medium](https://openai.com/index/openai-o3-mini/)                                                                                    | ✅ (experimental) | ❌                 |
| OpenAI       | [o3-mini-high](https://openai.com/index/openai-o3-mini/)                                                                                      | ✅ (experimental) | ❌                 |
| OpenAI       | [o3](https://platform.openai.com/docs/models#o3)                                                                                              | ✅                | ❌                 |
| OpenAI       | [o4-mini](https://platform.openai.com/docs/models/o4-mini)                                                                                    | ✅                | ❌                 |
| OpenAI       | [GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1)                                                                                    | ✅                | ✅                 |
| OpenAI       | [GPT-4.1-mini](https://platform.openai.com/docs/models/gpt-4o-mini)                                                                           | ✅                | ✅                 |
| OpenAI       | [GPT-4.1-nano](https://platform.openai.com/docs/models/gpt-4.1-nano)                                                                          | ✅                | ✅                 |
| Anthropic    | [Claude 3.5 Haiku](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)                                                   | ✅                | ❌                 |
| Anthropic    | [Claude Haiku 4.5](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                                           | ✅                | ✅                 |
| Anthropic    | [Claude Haiku 4.5 w/ Thinking](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                               | ✅                | ✅                 |
| Anthropic    | [Claude 3.7 Sonnet](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)                                                  | ✅                | ✅                 |
| Anthropic    | [Claude Sonnet 4](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                                            | ✅                | ✅                 |
| Anthropic    | [Claude Sonnet 4 w/ Thinking](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                                | ✅                | ✅                 |
| Anthropic    | [Claude Sonnet 4.5](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                                           | ✅                | ✅                 |
| Anthropic    | [Claude Sonnet 4.5 w/ Thinking](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                               | ✅                | ✅      
| Anthropic    | [Claude Opus 4.5](https://docs.anthropic.com/en/docs/about-claude/models/overview)                                                            | ✅                | ✅                 |
| Google       | [Gemini 1.5 Pro](https://deepmind.google/technologies/gemini/pro/)                                                                            | ✅ (beta)         | ✅\*               |
| Google       | [Gemini 2.0 Flash](https://deepmind.google/technologies/gemini/flash/)                                                                        | ✅                | ✅\*               |
| Google       | [Gemini 2.5 Pro](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro)                                                 | ✅                | ✅\*               |
| Google       | [Gemini 2.5 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash)                                             | ✅                | ✅\*               |
| Google       | [Gemini 3 Pro](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-pro)                                                | ✅                | ✅\*               |

<Callout type="note">
	* While Gemini models support vision capabilities, Cody clients do not
	currently support image uploads to Gemini models.
</Callout>

<Callout type="note">
	To use Claude 3 Sonnet models with Cody Enterprise, make sure you've
	upgraded your Sourcegraph instance to the latest version.{' '}
</Callout>

<Callout type="note">
	Site admins can configure vision support using the [`chatVision`
	setting](/admin/config/site-config) in site configuration and by adding the
	`vision` capability to model configurations. See [Model
	Configuration](/cody/enterprise/model-configuration) for more details.
</Callout>

### Claude 3.7 and 4 Models

Claude 3.7 and 4 Sonnet have two variants; the base version, and the **extended thinking** version which supports deep reasoning and fast, responsive edit workflows. Claude Haiku 4.5 also supports both variants. Cody enables using both, and lets the user select which to use in the model dropdown selector, so the user can choose whether to use extended thinkig depending on their work task.

<Callout type="note">
	Claude 4 models support is available with Sourcegraph versions v6.4+ and
	v6.3.4167. Claude Haiku 4.5 requires v6.9.2509+. Model availability also
	depends on the deployment type and whether it's **thinking** or not.
</Callout>

#### Claude 3.7 and 4 via Google Vertex, via AWS Bedrock

Starting in Sourcegraph v6.4+ and v6.3.416, Claude 3.7 Extended Thinking - as well as Claude 4 base and extended thinking variants - are available in Sourcegraph when using Claude through either Google Vertex or AWS Bedrock. Claude Haiku 4.5 is available starting in v6.9.2509.

See [Model Configuration: Reasoning models](/cody/enterprise/model-configuration#reasoning-models) for more information.

## Autocomplete

Cody uses a set of models for autocomplete which are suited for the low latency use case.

| **Provider** | **Model**                                                                                 | **Status** |
| :----------- | :---------------------------------------------------------------------------------------- | :--------- |
| Fireworks.ai | [DeepSeek-Coder-V2](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)   | ✅         |
| Anthropic    | [claude Instant](https://docs.anthropic.com/claude/docs/models-overview#model-comparison) | ✅         |

<Callout type="note">
	The default autocomplete model for Enterprise users is DeepSeek-Coder-V2.
</Callout>

<Callout type="note">
	The DeepSeek model used by Sourcegraph is hosted by Fireworks.ai, and is
	hosted as a single-tenant service in a US-based data center. For more
	information see our [Cody
	FAQ](https://sourcegraph.com/docs/cody/faq#is-any-of-my-data-sent-to-deepseek).
</Callout>

## Smart Apply

| **Provider** | **Model**      | **Status** |
| :----------- | :------------- | :--------- |
| Fireworks.ai | Qwen 2.5 Coder | ✅         |

Fireworks.ai is the default model for cody-gateway, but if you wish to switch to Claude models, Site admins can do it following these steps:

-   Go to **Site admin**
-   Click on the **Feature flags**
-   Search for `cody-smart-apply-instant-mode-enabled` feature flag
-   Turn off/delete the **cody-smart-apply-instant-mode-enabled** feature flag
