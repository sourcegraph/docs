# Agentic Chat

<p className="subtitle"> Learn about the Agentic Chat experience, an exclusive chat-based AI agent with enhanced capabilities.</p>

<Callout type="info">Agentic Chat is currently in the Experimental stage for Cody Pro and Enterprise and is supported only on VS Code, Visual Studio, JetBrains editor extensions, and Web.</Callout>

Cody's Agentic Chat experience is an AI agent that can evaluate context and fetch any additional context by providing enhanced, context-aware chat capabilities. It extends Cody's functionality by proactively understanding your coding environment and gathering relevant information based on your requests before responding. These features help you get noticeably higher-quality responses.

This Agentic Chat experience aims to reduce the learning curve associated with traditional coding assistants by minimizing users' need to provide context manually. It achieves this through agentic context retrieval, where the AI autonomously gathers and analyzes context before generating a response.

## Capabilities of Agentic Chat

The Agentic Chat experience leverages several key capabilities, including:

- **Proactive context gathering**: Automatically gathers relevant context from your codebase, project structure, and current task
- **Agentic context review**: Reviews the gathered context to ensure it is comprehensive and relevant to your query
- **Iterative context improvement**: Performs multiple review loops to refine the context and ensure a thorough understanding
- **Enhanced response accuracy**: Leverages comprehensive context to provide more accurate and relevant responses, reducing the risk of hallucinations

## Enable Agentic Chat

Pro users can enable the Agentic Chat experience from the green **funnel** icon in Cody's chat panel. You can toggle the **Agentic Chat** feature on and off. Enterprise customers are required to opt-in to get access to this Agentic Chat feature.

![Agentic chat interface](IMAGE LINK TO BE ADDED)

### Getting Agentic Chat access for Enterprise customers

Enterprise customers can get access by upgrading their supported client (VS Code, JetBrains, and Visual Studio) to the latest version of the plugin and enabling the following feature flags on their Sourcegraph Instance:

- `agentic-chat-experimental` to get access to the feature
- `agentic-chat-cli-tool-experimental` to allow [terminal access](#terminal-commands)
- Users will also need to manually enable access to the terminal commands on the client's `settings.json` file i.e., set `"cody.agentic.context.experimentalShell": true`

## What can Agentic Chat do?

Agentic Chat can help you with the following:

### Tool Usage

It has access to a suite of tools for retrieving relevant context. These tools include:

- **Code Search**: Performs code searches
- **Codebase File**: Retrieves the full content from a file in your codebase
- **Terminal**: Executes shell commands in your terminal
- **Chat Memory**: Allows the agent to create personal notes that can be used across chat sessions
- **Web Browser*: Searches the web for live context
- **OpenCtx**: Any OpenCtx providers could be used by the agent

It integrates seamlessly with external services, such as web content retrieval and issue tracking systems, using OpenCtx providers. To learn more, [read the OpenCtx docs](/cody/capabilities/openctx).

Memory allows the Agentic Chat to learn and remember your preferences, enabling a more personalized experience. You can ask it to **remember** specific details for future interactions.

<Callout type="info">Terminal access is not supported on the Web. It currently only works with VS Code and JetBrains editor extensions.</Callout>

## Terminal access

Agentic Chat can use the CLI Tool to request execution of shell commands in order to gather context from your terminal. Its ability to execute terminal commands enhances its context-gathering capabilities. However, it’s essential to understand that any information accessible via your terminal could potentially be shared with the LLM. It's recommended not to request information that you don't want to share. Here's what you should consider:
* - **Requires user consent**: Agentic Chat will pause and ask for permission each time before executing any shell command.
- **Trusted workspaces only**: Commands can only be executed within trusted workspaces with a valid shell
- **Potential data sharing**: Any terminal-accessible information may be shared with the LLM

Commands are generated by the agent/LLM based on your request. Avoid asking it to execute destructive commands.

### Configure shell command execution

You can configure shell command execution via the `cody.agentic.context` setting in your editor:

#### Enable Agentic Chat access to CLI

Update the `cody.agentic.context` setting to `allow` or `block` specific commands:

```json
{
  "cody.agentic.context": {
    "shell": {
  // Array of allowed command prefixes, or ["*"] for all commands
      "allow": ["git", "gh", "ls"],
      "block": ["git"] // Additional commands to block
    }
  }
}
```

#### Disable Agentic Chat access to CLI

To disable the feature, navigate to your user settings and set `cody.agentic.context` to an empty value. When disabled, the chat agent cannot access the CLI.

## Use cases

Agentic Chat can be helpful to assist you with a wide range of tasks, including:

- **Improved response quality**: Helps you get better and more accurate responses than other LLMs, making the additional processing time for context gathering a non-issue
- **Error resolution**: It can automatically identify error sources and suggest fixes by analyzing error logs
- **Better unit tests**: Automatically includes imports and other missing contexts to generate better unit tests

## Known limitations

### Enterprise deployments

Cody Gateway customers are required to have Claude 3.5 Haiku enabled (this requires Sourcegraph v5.9 and new [model configuration](/cody/enterprise/model-configuration)). BYOK customers will use the selected models, but the quality may vary.

### Security concerns

As mentioned above, Agentic Chat's ability to execute terminal commands enhances its context-gathering capabilities. However, it’s essential to understand that any information accessible via your terminal could be shared with the LLM.
