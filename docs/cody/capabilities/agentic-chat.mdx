# Agentic Chat

<p className="subtitle"> Learn about the Agentic Chat experience, an exclusive chat-based AI agent with enhanced capabilities.</p>

<Callout type="info">Agentic Chat is currently in the Experimental stage and is supported only on VS Code, JetBrains editor extensions, and Web.</Callout>

Cody's Agentic Chat experience is an AI agent that can evaluate context and fetch any additional context by providing enhanced, context-aware chat capabilities. It extends Cody's functionality by proactively understanding your coding environment and gathering relevant information based on your requests before responding. These features help you get noticeably higher-quality responses.

This Agentic Chat experience aims to reduce the learning curve associated with traditional coding assistants by minimizing users' need to provide context manually. It achieves this through agentic context retrieval, where the AI autonomously gathers and analyzes context before generating a response.

## Capabilities of Agentic Chat

The Agentic Chat experience leverages several key capabilities, including:

- **Proactive context gathering**: Automatically gathers relevant context from your codebase, project structure, and current task
- **Agentic context review**: Reviews the gathered context to ensure it is comprehensive and relevant to your query
- **Iterative context improvement**: Performs multiple review loops to refine the context and ensure a thorough understanding
- **Enhanced response accuracy**: Leverages comprehensive context to provide more accurate and relevant responses, reducing the risk of hallucinations

## Enable Agentic Chat

You can enable the Agentic Chat experience from the green **funnel** icon in Cody's chat panel. You can toggle the **Agentic Chat** feature on and off. Enterprise customers are required to opt-in to get access to this Agentic Chat feature.

![Agentic chat interface](IMAGE LINK TO BE ADDED)

### Getting Agentic Chat access for Enterprise customers

Enterprise customers can get access by upgrading their client (VS Code or JetBrains) to the latest version of the plugin and enabling the following feature flags on their Sourcegraph Instance:

- `deep-cody` to get access to the feature
- `deep-cody-shell-context` to allow [terminal access](#terminal-commands)
- Users will also need to manually enable access to the terminal commands on the client's `settings.json` file i.e., set `"cody.agentic.context.experimentalShell": true`

## What can Agentic Chat do?

Agentic Chat can help you with the following:

### Tool Usage

It has access to a suite of tools for retrieving relevant context. These tools include:

- **Search Tool**: Searches the codebase using keywords extracted from your query
- **File Tool**: Retrieves the content of specific files in your codebase
- **CLI Tool**: Executes terminal commands to gather system or project-specific information
- **Memory Tool**: Allows the agent to create personal notes that can be used across chat sessions
- **Web Browser Tool (via OpenCtx)**: Searches the web for live context
- **Linear Issue Tool (via OpenCtx)**: Integrates with Linear issue tracking when the provider is configured

It integrates seamlessly with external services, such as web content retrieval and issue tracking systems, using OpenCtx providers. To learn more, [read the OpenCtx docs](/cody/capabilities/openctx).

Memory allows the Agentic Chat to learn and remember your preferences, enabling a more personalized experience. You can ask it to **remember** specific details for future interactions.

<Callout type="info">Tool calling is not supported on the Web. It only works with VS Code and JetBrains editor extensions.</Callout>

## Terminal commands

Agentic Chat can use the CLI Tool to execute shell commands and gather context from your terminal. Its ability to execute terminal commands enhances its context-gathering capabilities. However, it’s essential to understand that any information accessible via your terminal could potentially be shared with the LLM. It's recommended not to request information that you don't want to share. Here's what you should consider:

- **Trusted workspaces only**: Commands can only be executed within trusted workspaces with a valid shell
- **Potential data sharing**: Any terminal-accessible information may be shared with the LLM
- **Allow list configuration**: This feature is disabled if the allow list is empty. By default, the allow list is set to ['*'], which allows all commands. For enhanced security, use specific command prefixes instead of the wildcard *.

Commands are generated by the agent/LLM based on your request. Avoid asking it to execute destructive commands if you do not want them to run.

## Configure shell command execution

You can configure shell command execution via the `cody.agentic.context` setting in your editor:

### Enable Agentic Chat access to CLI

Update the `cody.agentic.context` setting to `allow` or `block` specific commands:

```json
{
  "cody.agentic.context": {
    "shell": {
  // Array of allowed command prefixes, or ["*"] for all commands
      "allow": ["git", "gh", "ls"],
      "block": ["git"] // Additional commands to block
    }
  }
}
```

### Disable Agentic Chat access to CLI

To disable the feature, navigate to your user settings and set `cody.agentic.context` to an empty value. When disabled, the chat agent cannot access the CLI.

## Use cases

Agentic Chat can be helpful to assist you with a wide range of tasks, including:

- **Improved response quality**: Helps you get better and more accurate responses than other LLMs, making the additional processing time for context gathering a non-issue
- **Error resolution**: It can automatically identify error sources and suggest fixes by analyzing error logs
- **Better unit tests**: Automatically includes imports and other missing contexts to generate better unit tests

## Known limitations

### Enterprise deployments

Cody Gateway customers are required to have Claude 3.5 Haiku enabled (this requires Sourcegraph v5.9 and new [model configuration](/cody/enterprise/model-configuration)). BYOK customers will use the selected models, but the quality may vary.

### Security concerns

As mentioned above, Agentic Chat's ability to execute terminal commands enhances its context-gathering capabilities. However, it’s essential to understand that any information accessible via your terminal could be shared with the LLM.
