# Sourcegraph Cody Gateway

<p className="subtitle">Learn how Cody Gateway powers the default Sourcegraph provider for completions to facilitate Cody features.</p>

<Callout type="note" title="Note">Cody Gateway is supported for Sourcegraph Enterprise customers on v5.1 or more.</Callout>

Sourcegraph Cody Gateway powers the default `"provider": "sourcegraph"` and Cody completions for Sourcegraph Enterprise users. It supports a variety of upstream LLM providers, such as [Anthropic](https://www.anthropic.com/) and [OpenAI](https://openai.com/), with rate limits, quotas, and model availability tied to your Sourcegraph Enterprise subscription.

## Using Cody Gateway in Sourcegraph Enterprise

To enable completions provided by Cody Gateway on your Sourcegraph Enterprise instance, make sure your license key is set, and Cody is enabled in your [site configuration](/admin/config/site_config):

```jsonc
{
  "licenseKey": "<...>",
  "cody.enabled": true,
}
```

After adding the license key, the default configuration and authentication will be automatically applied.

For more details about configuring Cody, read the following resources:

- [Enabling Cody for Sourcegraph Enterprise](/cody/clients/enable-cody-enterprise)

Cody Gateway is hosted at `cody-gateway.sourcegraph.com`. To use Cody Gateway, your Sourcegraph instance must be connected to the service in this domain.

<Callout type="warning">Sourcegraph Cody Gateway access must be included in your Sourcegraph Enterprise subscription. You can verify it by checking it with your account manager. If you are a [Sourcegraph Cloud](/cloud/) user, Cody is enabled by default on your instance starting with Sourcegraph 5.1.</Callout>

## Configuring custom models

To configure custom models for various Cody configurations (for example, `"completions"`), specify the desired model with the upstream provider as a prefix to the name of the model. For example, to use the `claude-2` model from Anthropic, you would configure:

```json
{
  "completions": { "chatModel": "anthropic/claude-2.0" },
}
```

The currently supported upstream providers for models are:

- [`anthropic/`](https://www.anthropic.com/)
- [`openai/`](https://openai.com/)

For Sourcegraph Enterprise customers, model availability depends on your Sourcegraph Enterprise subscription.

<Callout type="warning">When using OpenAI models for completions, only chat completions will work - code completions are currently unsupported.</Callout>

## Rate limits and quotas

Rate limits, quotas, and model availability are tied to your Sourcegraph Enterprise license for Sourcegraph Enterprise instances.

All successful requests to Cody Gateway will count toward your rate limits. Unsuccessful requests are not counted as usage.

Rate limits, quotas, and model availability are also configured per Cody feature - for example, you will have separate rate limits for Cody chat and completions.

In addition to the above, we may throttle concurrent requests to Cody Gateway per Sourcegraph Enterprise instance or Cody App user to prevent excessive burst consumption.

<Callout type="note">You can reach out for more details about Sourcegraph Cody Gateway access available to you and how you can gain access to higher rate limits, quotas, and/or model options.</Callout>

## Privacy and security

Sourcegraph Cody Gateway does not retain sensitive data (prompt test and source code included in requests, etc.) from any traffic received. Only rate limit consumption per Sourcegraph Enterprise license and some high-level diagnostic data (error codes from upstream, numeric/enum request parameters, etc) are tracked.

For more details about Cody Gateway security practices, please reach out to your account manager. You can also refer to the [Cody usage and privacy notice](https://about.sourcegraph.com/terms/cody-notice) for more privacy details about Cody in general.
