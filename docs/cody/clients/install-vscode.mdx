# Installing Cody in VS Code

<p className="subtitle">Learn how to use Cody and its features with the VS Code editor.</p>

The Cody extension by Sourcegraph enhances your coding experience in VS Code by providing intelligent code suggestions, context-aware autocomplete, and advanced code analysis. This guide will walk you through the steps to install and set up Cody within your VS Code environment.

<LinkCards>
  <LinkCard href="https://marketplace.visualstudio.com/items?itemName=sourcegraph.cody-ai" imgSrc="https://storage.googleapis.com/sourcegraph-assets/docs/images/cody/vscode.svg" imgAlt="Cody for VS Code" title="Cody for VS Code" description="Install Cody's free extension for VS Code." />
</LinkCards>

## Prerequisites

- You have the latest version of [VS Code](https://code.visualstudio.com/) installed
- You have a Free or Pro account via Sourcegraph.com or a Sourcegraph Enterprise account

## Install the VS Code extension

Follow these steps to install the Cody AI extension for VS Code:

- Open VS Code editor on your local machine
- Click the **Extensions** icon in the Activity Bar on the side of VS Code, or use the keyboard shortcut `Cmd+Shift+X` (macOS) or `Ctrl+Shift+X` (Windows/Linux)
- Type **Cody AI** in the search bar and click the **Install** button
- After installing, you may be prompted to reload VS Code to activate the extension

<img
  src="https://storage.googleapis.com/sourcegraph-assets/Docs/install-cody-vscode.png"
  alt="Screenshot of Cody for VS Code marketplace install page"
  style={{ aspectRatio: '2630 / 802' }}
/>

Alternatively, you can also [download and install the extension from the VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=sourcegraph.cody-ai) directly.

## Connect the extension to Sourcegraph

After a successful installation, the Cody icon appears in the [Activity sidebar](https://code.visualstudio.com/api/ux-guidelines/activity-bar).

### Cody Free or Cody Pro Users

Cody Free and Cody Pro users can sign in to their Sourcegraph.com accounts through GitHub, GitLab, or Google.

<img
  src="https://storage.googleapis.com/sourcegraph-assets/Docs/cody-new-ui.png"
  alt="Cody for VS Code sign in flow"
  style={{ aspectRatio: '1296 / 671' }}
/>

### Sourcegraph Enterprise Cody Users

<Callout type="info"> If you are using an older version of Cody, uninstall it and reload VS Code. It's always recommended to install the latest version before proceeding to next steps.</Callout>

Sourcegraph Enterprise users should connect Cody to their Enterprise instance by clicking **Sign In to Your Enterprise Instance**.

You'll be prompted to choose how to sign-in, select **Sign In to Sourcegraph Instances v5.1 and above**.

<img
  src="https://storage.googleapis.com/sourcegraph-assets/Docs/927fb401aa80af47f4384a854309b0ed5ac58da34507ed4c0dfd72da61e1edfb.png"
  alt="Sign in options"
  style={{ aspectRatio: '1212 / 282' }}
/>

Enter the URL of your Enterprise instance. If you are unsure, please contact your administrator.

<img
  src="https://storage.googleapis.com/sourcegraph-assets/Docs/c8fc65594ac718cfc6e6d67e76af8dd8989c8dd6300725f5afd872210f76e786.png"
  alt="Instance URL"
  style={{ aspectRatio: '1210 / 150' }}
/>

A pop-up will ask if you want to Open the URL in a new window. Click **Open** to open the URL in a new window.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/0c72d6a8e48a28bb6543d5dd333187ae130743937e584b67bd3a42b810e9ec69.png"
	alt="Cody for VS Code sign in permissions dialog"
	style={{ aspectRatio: '536 / 712' }}
	/>

Sign in to your instance. If you do not yet have a login, please contact your administrator.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/3b66de59129d19d8e71ed4d07b1e369ac956b7e3177cb8d3af60765559842431.png"
	alt="Sign in"
	style={{ aspectRatio: '784 / 806' }}
	/>

Create an access token from Account Settings - Access Tokens. Click **+ Generate new token**

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/a88d828e082067ac6c57f8c32d67de3bf093732689578a4aa29c5b2f67fd53ba.png"
	alt="Creating an access token"
	style={{ aspectRatio: '2252 / 448' }}
	/>

Name the token and click **+ Generate token**.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/6e2255ea122a5b1840d0ce7c032e26742540b7a2a610ab95d47e969b9f94e3f4.png"
	alt="Token name"
	style={{ aspectRatio: '1808 / 638' }}
	/>

Copy the token and return to VSCode.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/707e642d4cf84aba4134cb83d2bdc0c1280f847d0909c144aaf43e004de3a945.png"
	alt="Copying the token"
	style={{ aspectRatio: '1816 / 926' }}
	/>

Again, click **Sign In to Your Enterprise Instance** and choose **Sign In to Sourcegraph Instances v5.1 and above**. Enter the URL of your instance.

You should now be prompted to authorize Sourcegraph to connect to your VSCode extension using the token you created. Click **Authorize**.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/78651f94c061ba7a63041893a73705b5b5568587830831f68b3afee1f02ca744.png"
	alt="Authorization permission dialog"
	style={{ aspectRatio: '780 / 1086' }}
	/>

Finally, you will be asked to allow the extension access. CLick **Open**.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/946384c3bbce7790dc119ecec2d1540fcb3e50dc007eee4472c0bcac8b14c251.png"
	alt="VS Code allow permissions dialog"
	style={{ aspectRatio: '572 / 630' }}
	/>

VSCode should now display the Cody panel and you're ready to go.

## Verifying the installation

Once connected, click the Cody icon from the sidebar again. The Cody extension will open in a configurable side panel.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/NLS-Beta.png"
	alt="Cody for VS Code"
	style={{ aspectRatio: '1306 / 1940' }}
	/>

Let's create an autocomplete suggestion to verify that the Cody extension has been successfully installed and is working as expected.

Cody provides intelligent code suggestions and context-aware autocompletions for numerous programming languages like JavaScript, Python, TypeScript, Go, etc.

- Create a new file in VS Code, for example, `code.js`
- Next, type the following algorithm function to sort an array of numbers

```js
function bubbleSort(array){

}
```

- As you start typing, Cody will automatically provide suggestions and context-aware completions based on your coding patterns and the code context
- These autocomplete suggestions appear as grayed text. To accept the suggestion, press the `Tab` key

    <video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
          <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/cody-in-action.mp4" type="video/mp4" />
          </video>

## Chat

Cody chat in VS Code is available in a tab next to your code. Once connected to Sourcegraph, a **New Chat** button opens the chat window on the right. You can have multiple Cody Chats going simultaneously in separate tabs.

All previous and existing chats are stored under the chats panel on the left. You can download these to share or use later in a `.json` file, or delete them altogether.

### Chat history

There is a **Chat History** button at the top of your chat tabs, so you can navigate between chats (and search chats) without opening the Cody sidebar.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/blog/vscode-v1-2-0-blog/image-002.png"
	alt="Cody command menu"
	style={{ aspectRatio: '1942 / 1086' }}
	/>

### Chat interface

The chat interface is designed intuitively, which makes it easier to edit chat messages or start a new chat quickly. You can hit **Enter** to edit your message immediately without waiting for the stream to finish. This allows for quicker experimentation and iteration and less dependence on sending follow-up messages to clarify your question (which can also fill up your chat's context window).

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/Chat_%20Redesigned%20chat%20editing.mp4" type="video/mp4" />
</video>

### Changing model used
NOTE: You need to be a Cody Pro user to have multi-model selection capability. This is not available for Cody Free or Cody Enterprise users

For Chat:
1. Open a new chat window (Opt + L)
1. Click on the model selector (which by default indicates Claude 3 Sonnet)
1. See selection of models and click the model you desire. This model will now be the default model going forward on any new chats.

For Edit:
1. On any file select some code and do a right-click
1. Select Cody->Edit Code (optionally you can do this with Opt+K/Alt+K)
1. Select the default model available (at the time of writing this is Claude 3 Opus)
1. See selection of models and click the model you desire. This model will now be the default model going forward on any new edits.

### Selecting Context with @-mentions

Cody's chat allows you to add files and symbols as context in your messages.

- Type `@-file` and then a filename to include a file as context
- Type `@#` and then a symbol name to include the symbol's definition as context. Functions, methods, classes, types, etc., are all symbols

The `@-file` also supports line numbers to query the context of large files. You can add ranges of large files to your context by @-mentioning a large file and appending a number range to the filename, for example, `@filepath/filename:1-10`.

When you `@-mention` files to add to Cody’s context window, the file lookup takes `files.exclude`, `search.exclude`, and `.gitgnore` files into account. This makes the file search faster as a result up to 100ms.

Moreover, when you `@-mention` files, Cody will track the number of characters in those files against the context window limit of the selected chat model. As you `@-mention` multiple files, Cody will calculate how many tokens of the context window remain. When the remaining context window size becomes too small, you get **File too large** errors for further more `@-mention` files.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/blog/cody-vscode-1.8.0/@file-line-numbers.gif"
	alt="Cody chat interface @'ing a file"
	style={{ aspectRatio: '782 / 580' }}
	/>

## Context fetching mechanism

VS Code users on the Free or Pro plan can leverage [local context](/cody/core-concepts/context#context-selection) (local keyword search) as the primary context source for Cody chat with access to local embeddings. Remote embeddings will no longer be produced or used as a context source.

Enterprise users can leverage the full power of the Sourcegraph search engine as the primary context provider to Cody.

<Callout type="info"> Read more about [Context fetching mechanism](/cody/core-concepts/context/#context-fetching-mechanism) in detail.</Callout>

## Context scope

VS Code users on the Free or Pro plan get single-repo support and can use one repo for context fetching. Enterprise users get multi-repo support and can explicitly specify **up to 10 additional repos** they would like Cody to use for context.

### Enhanced Context Selector

Cody's Enhanced Context enables Cody to leverage search and embeddings-based context. Community users can generate local embeddings for their projects by clicking the icon next to the chat input. Users can also disable Enhanced Context or configure more granular control of Cody’s context by including `@-files` or `@#-symbols` in the chat input. This feature only supports local files and paths relative to your workspace. Start typing `@`, and Cody will suggest files for you to include.

<Callout type="note">Enhanced context selector offers single-repo support for Cody Free and Pro while multi-repo support for Cody Enterprise.</Callout>

<img
	src="https://storage.googleapis.com/sourcegraph-assets/Docs/enhanced-context-imp.png"
	alt="Enhanced context popover"
	style={{ aspectRatio: '1320 / 546' }}
	/>

The following tables shows what happens when Enhanced Context Selection is enabled or disabled.

|                           | Opened Files | Highlighted Code | Embeddings (If available) | Search (as backup) |     |
| ------------------------- | ------------ | ---------------- | ------------------------- | ------------------ | --- |
| Enhanced Context Enabled  | ✅            | ✅                | ✅                         | ✅                  |     |
| Enhanced Context Disabled | ❌            | ❌                | ❌                         | ❌                  |     |

### Add files as context from the file tree

You can add files as context to the Cody chat directly from the folder hierarchy. To do so, right-click any file from the folder and click the **Add File to Cody Chat** option. The selected file path will populate as an `@-mention` entry in the chat window to fetch context.

If your Cody chat window is not open, this option will appear as **New Chat with File** when you right-click any file.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/vscode-context-file-tree.mp4" type="video/mp4" />
</video>

## Commands

Cody offers quick, ready-to-use [Commands](/cody/capabilities/commands) for common actions to write, describe, fix, and smell code. These allow you to run predefined actions with smart context-fetching anywhere in the editor, like:

- Ask Cody a question
- Add code documentation
- Edit code with instructions
- Explain code
- Identify code smells
- Generate unit tests
- Custom commands

Let's understand how the `/doc` command generates code documentation for a function.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/code-comments-cody.mp4" type="video/mp4" />
</video>

### Custom Commands

<Callout type="note">Custom Commands are currently available in Beta for all users and are currently supported by Cody for the VS Code extension version 0.8 and above.</Callout>

For customization and advanced use cases, you can create **Custom Commands** tailored to your requirements. You can also bind keyboard shortcuts to run your custom commands quickly. To bind a keyboard shortcut, open the Keyboard Shortcuts editor and search for `cody.command.custom.` to see the list of your custom commands.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/blog/cody-vscode-1.8.0/keybindings.png"
	alt="Settings"
	style={{ aspectRatio: '1059 / 228' }}
	/>

<Callout type="info">Learn more about Custom Commands [here](/cody/capabilities/commands#custom-commands)</Callout>

## Cody Natural Language Search

<Callout type="note">Cody Natural Language Search is currently available in Beta for all users on VS Code extension.</Callout>

Cody's **Natural Language Search** is an AI-powered code search that allows users to input a natural language search query and look for it within their project. For example, "password hashing" or "connection retries".

In the left-hand panel, type your queries in the **Search** field, and the search results are displayed. You can select one of the search results and verify that the correct file opens in a new tab. Natural Language Search works for all Cody users with the ability to search across your entire local codebase from within the IDE.

## Updating the extension

VS Code will typically notify you when updates are available for installed extensions. Follow the prompts to update the Cody AI extension to the latest version.

## Authenticating Cody with VS Code forks

Cody also works with Cursor, Gitpod, IDX, and other similar VS Code forks. To access VS Code forks like Cursor, select **Sign in with URL and access token** and generate an access token. Next, copy and paste into the allocated field, using `https://sourcegraph.com` as the URL.

## Supported LLM models

Claude 3 Sonnet is the default LLM model for Cody Free users for Chat and Commands. Users on Cody **Pro** can choose from a list of supported LLM models for Chat, Commands, and Autocomplete. These LLMs are Claude Instant, Claude 2.0, Claude 2.1, Claude 3 (Haiku, Opus and Sonnet), ChatGPT 3.5 Turbo, ChatGPT 4 Turbo Preview, GPT-4o and Mixtral.

<img
	src="https://storage.googleapis.com/sourcegraph-assets/blog/cody-vscode-1.8.0/claude3-2.png"
	alt="Choosing an chat model"
	style={{ aspectRatio: '1330 / 624' }}
	/>

Cody Enterprise users get Claude 3 (Opus and Sonnet) as the default LLM models without extra cost. In addition, Enterprise users also get capabilities like BYOLLM (Bring Your Own LLM) key. Your site administrator determines the LLM; you cannot change it from the editor. However, when using Cody Gateway, you can [configure custom models](/cody/core-concepts/cody-gateway#configuring-custom-models) Anthropic (like Claude 2.0 and Claude Instant) and OpenAI (GPT 3.5 and GPT 4).

<Callout type="note">To use Claude 3 (Opus and Sonnets) models with Cody Enterprise, make sure you've upgraded your Sourcegraph instance to the latest version.</Callout>

## Supported local Ollama models with Cody

<Callout type="info">Support with Ollama is currently in the Experimental stage and is available for Cody Free and Pro plans.</Callout>

### Cody Autocomplete with Ollama

To generate autocomplete suggestions with Ollama locally, follow these steps:

- Install and run [Ollama](https://ollama.ai/)
- Download one of the support local models:
  - `ollama pull deepseek-coder:6.7b-base-q4_K_M` for [deepseek-coder](https://ollama.ai/library/deepseek-coder)
  - `ollama pull codellama:7b-code` for [codellama](https://ollama.ai/library/codellama)
- Update Cody's VS Code settings to use the `experimental-ollama` autocomplete provider and configure the right model:

```json

   {
     "cody.autocomplete.advanced.provider": "experimental-ollama",
     "cody.autocomplete.experimental.ollamaOptions": {
       "url": "http://localhost:11434",
       "model": "deepseek-coder:6.7b-base-q4_K_M"
     }
   }
```

- Confirm Cody uses Ollama by looking at the Cody output channel or the autocomplete trace view (in the command palette)

#### Cody Chat and Commands with Ollama

<img
	src="https://storage.googleapis.com/sourcegraph-assets/blog/cody-vscode-1.8.0/localollama.png"
	alt="Chat model selector"
	style={{ aspectRatio: '1110 / 443' }}
	/>

To generate chat and commands with Ollama locally, follow these steps:

- Download [Ollama](https://ollama.com/download)
- Start Ollama (make sure the Ollama logo is showing up in your menu bar)
- Select a chat model (model that includes instruct or chat, for example, [gemma:7b-instruct-q4_K_M](https://ollama.com/library/gemma:7b-instruct-q4_K_M)) from the [Ollama Library](https://ollama.com/library)
- Pull the chat model locally (for example, `ollama pull gemma:7b-instruct-q4_K_M`)
- Once the chat model is downloaded successfully, open Cody in VS Code
- Enable the `cody.experimental.ollamaChat` configuration
- Open a new Cody chat
- In the new chat panel, you should see the chat model you've pulled in the dropdown list
- Currently, you will need to restart VS Code to see the new models

<Callout type="note">You can run `ollama list` in your terminal to see what models are currently available on your machine.</Callout>

## Experimental models

<Callout type="info">Support for the following models is currently in the Experimental stage, and available for Cody Free and Pro plans.</Callout>

The following experimental model providers can be configured in Cody's extension settings JSON:

- Google (requires [Google AI Studio API key](https://aistudio.google.com/app/apikey))
- Groq (requires [GroqCloud API key](https://console.groq.com/docs/api-keys))
- OpenAI & OpenAI-Compatible API (requires [OpenAI API key](https://platform.openai.com/account/api-keys))
- Ollama (remote)

Once configured, and VS Code has been restarted, you can select the configured model from the dropdown both for chat and for edits.

Example VS Code user settings JSON configuration:

```json
{
  "cody.dev.models": [
    // Google (e.g. Gemini 1.5 Pro)
    {
      "provider": "google",
      "model": "gemini-1.5-pro-latest",
      "tokens": 1000000,
      "apiKey": "xyz"
    },
    // Groq (e.g. llama2 70b)
    {
      "provider": "groq",
      "model": "llama2-70b-4096",
      "tokens": 4096,
      "apiKey": "xyz"
    },
    // OpenAI & OpenAI-compatible APIs
    {
      "provider": "groq", // keep groq as provider
      "model": "some-model-id",
      "apiKey": "xyz",
      "apiEndpoint": "https://host.domain/path"
    },
    // Ollama (remote)
    {
      "provider": "ollama",
      "model": "some-model-id",
      "apiEndpoint": "https://host.domain/path"
    }
  ]
}
```

### Provider configuration options

- `provider`: `"google"`, `"grok"` or `"ollama"`
  - The LLM provider type.
- `model`: `string`
  - The ID of the model, e.g. `"gemini-1.5-pro-latest"`
- `tokens`: `number` - optional
  - The context window size of the model. Default: `7000`.
- `apiKey`: `string` - optional
  - The API key for the endpoint. Required if the provider is `"google"` or `"groq"`.
- `apiEndpoint`: `string` - optional
  - The endpoint URL, if you don't want to use the provider’s default endpoint.

### Debugging experimental models

To debug problems with the experimental models, use the VS Code output panel which can be opened using the following steps:

- Open the Cody Sidebar
- Next to "Settings and Support" click the "..." icon
- Click "Open Output Channel"
