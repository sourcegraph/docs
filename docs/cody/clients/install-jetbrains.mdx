# Installing Cody for JetBrains

<p className="subtitle">Learn how to use Cody and its features with the JetBrains IntelliJ editor.</p>

The Cody extension by Sourcegraph enhances your coding experience in your IDE by providing intelligent code suggestions, context-aware completions, and advanced code analysis. This guide will walk you through the steps to install and set up Cody within your JetBrains environment.

<LinkCards>
   <LinkCard href="https://plugins.jetbrains.com/plugin/9682-cody-ai-by-sourcegraph" imgSrc="https://storage.googleapis.com/sourcegraph-assets/docs/images/cody/jb_beam.svg" imgAlt="Cody for JetBrains" title="JetBrains Extension" description="Install Cody's free extension for JetBrains." />
</LinkCards>

## Prerequisites

- You have the latest version of <a href="https://www.jetbrains.com/idea/" target="_blank">JetBrains IDEs</a> installed
- You have a Free or Pro account via Sourcegraph.com or a Sourcegraph Enterprise account
- Cody is compatible with the following JetBrains IDEs:
  - [Android Studio](https://developer.android.com/studio)
  - [AppCode](https://www.jetbrains.com/objc/)
  - [CLion](https://www.jetbrains.com/clion/)
  - [DataGrip](https://www.jetbrains.com/datagrip/)
  - [GoLand](https://www.jetbrains.com/go/)
  - [IntelliJ IDEA](https://www.jetbrains.com/idea/) (Community and Ultimate editions)
  - [PhpStorm](https://www.jetbrains.com/phpstorm/)
  - [PyCharm](https://www.jetbrains.com/pycharm/) (Community and Professional editions)
  - [Rider](https://www.jetbrains.com/rider/)
  - [RubyMine](https://www.jetbrains.com/ruby/)
  - [WebStorm](https://www.jetbrains.com/webstorm/)

## Install the JetBrains IntelliJ Cody extension

Follow these steps to install the Cody plugin:

- Open JetBrains IntelliJ editor on your local machine
- Open **Settings** (Mac: `⌘+,` Windows: `Ctrl+Alt+S`) and select **Plugins**
- Type and search **Cody: AI Coding Assistant with Autocomplete & Chat** extension and click **Install**

![cody-for-intellij](https://storage.googleapis.com/sourcegraph-assets/Docs/cody-for-intellij-062024.png)

Alternatively, you can [Download and install the extension from the Jetbrains marketplace](https://plugins.jetbrains.com/plugin/9682-sourcegraph).

## Connect the extension to Sourcegraph

After a successful installation, Cody's icon appears in the sidebar. Clicking it prompts you to start with codehosts like GitHub, GitLab, and your Google login. This allows Cody to access your Sourcegraph.com account.

Alternatively, you can also click the **Sign in with an Enterprise Instance** to connect to your enterprise instance.

![cody-for-intellij-login](https://storage.googleapis.com/sourcegraph-assets/Docs/Media/sign-in-cody-jb.png)

### For Sourcegraph Enterprise users

To connect the extension with your Enterprise instance,

- Click **Sign in with an Enterprise Instance**
- Enter the server for your enterprise instance (e.g. `https://<your-instance>.sourcegraph.com`)
- Select **Generate new token**. You'll be directed to the **Access tokens** page on your instance in the browser
- Generate a new token, copy it, and paste it into the **Token** field in your editor
- Click **Sign in**

### For Sourcegraph.com users

For Cody Free and Cody Pro users, you can Log in through SSO to authenticate the IntelliJ extension with your Sourcegraph.com account.

## Verifying the installation

Once Cody is successfully connected, you'll see that the sign-in panel has been replaced by a welcome message from Cody. Let's create an autocomplete suggestion to verify that the Cody extension has been successfully installed and is working as expected.

Cody provides intelligent code suggestions and context-aware autocompletions for numerous programming languages like JavaScript, Python, TypeScript, Go, etc.

- Create a new file in IntelliJ, for example, `code.js`
- Next, type the following algorithm function to sort an array of numbers

```js
function bubbleSort(array)
```

- As you start typing, Cody will automatically provide suggestions and context-aware completions based on your coding patterns and the code context
- These autocomplete suggestions appear as grayed text. To accept the suggestion, press the `Tab` key

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/jb-suggest-062024.mp4" type="video/mp4"/>
</video>

## Chat

Cody chat in JetBrains is available in a unified interface opened right next to your code. Once connected to Sourcegraph, a new chat input field is opened with a default `@-mention` [context chips](#context-retrieval).

All your previous and existing chats are stored for later use and can be accessed via the **History** icon from the top menu. You can download them to share or use later in a `.json` file or delete them altogether.

### Chat interface

The chat interface is designed intuitively. Your very first chat input lives at the top of the panel, and the first message in any chat log will stay pinned to the top of the chat. After your first message, the chat input window moves to the bottom of the sidebar.

Since your first message to Cody anchors the conversation, you can return to the top chat box anytime, edit your prompt, or re-run it using a different LLM model.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/jb-chat-interface-0824.mp4" type="video/mp4" />
</video>

### Changing LLM model for chat

<Callout type="note"> You need to be a Cody Free or Pro user to have multi-model selection capability. Enterprise users with the new [model configuration](/cody/clients/model-configuration) can use the LLM selection dropdown to choose a chat model.</Callout>

For Chat:

- Open chat or toggle between editor and chat
- Click on the model selector (which by default indicates Claude 3.5 Sonnet)
- See the selection of models and click the model you desire. This model will now be the default model going forward on any new chats

For Edit:

- On any file, select some code and a right-click
- Select **Cody > Edit Code**
- Select the default model available (this is Claude Sonnet 3.5)
- See the selection of models and click the model you desire. This model will now be the default model going forward on any new edits

## Supported LLM models

Users on Cody **Free** and **Pro** can choose from a list of supported LLM models for Chat and Commands. Both Cody Free and Pro users can choose from a list of supported LLM models for Chat and Commands.

![llm-selection-cody](https://storage.googleapis.com/sourcegraph-assets/Docs/jb-llm-select-0824.jpg)

Enterprise users get Claude 3 (Opus and Sonnet) as the default LLM models without extra cost. Moreover, Enterprise users can use Claude 3.5 models through Cody Gateway, Anthropic BYOK, AWS Bedrock (limited availability), and GCP Vertex.

<Callout type="info">For enterprise users on AWS Bedrock: 3.5 Sonnet is unavailable in `us-west-2` but available in `us-east-1`. Check the current model availability on AWS and your customer's instance location before switching. Provisioned throughput via AWS is not supported for 3.5 Sonnet.</Callout>

You also get additional capabilities like BYOLLM (Bring Your Own LLM), supporting Single-Tenant and Self Hosted setups for flexible coding environments. Your site administrator determines the LLM, and cannot be changed within the editor. However, Cody Enterprise users when using Cody Gateway have the ability to [configure custom models](/cody/core-concepts/cody-gateway#configuring-custom-models) Anthropic (like Claude 3 Opus and Claude Haiku), OpenAI (GPT 3.5 Turbo and GPT 4 Turbo) and Google Gemini 1.5 models (Flash and Pro).

<Callout type="note">Read and learn more about the [supported LLMs](/cody/capabilities/supported-models) and [token limits](/cody/core-concepts/token-limits) on Cody Free, Pro and Enterprise.</Callout>

## Ollama model support

<Callout type="note">Ollama support for JetBrains is in the Experimental stage and is available on Cody Free and Pro.</Callout>

You can use Ollama models locally for Cody’s chat and commands. This lets you chat without sending messages over the internet to an LLM provider so that you can use Cody offline. To use Ollama locally, you’ll need to install Ollama and download a chat model such as CodeGemma or Llama3. [Read here for detailed instructions](https://sourcegraph.com/github.com/sourcegraph/jetbrains/-/blob/README.md#use-ollama-models-for-chat--commands).

## Smart Apply code suggestions

Cody lets you dynamically insert code from chat into your files with **Smart Apply**. Every time Cody provides you with a code suggestion, you can click the **Apply** button. Cody will then analyze your open code file, find where that relevant code should live, and add a diff.

For chat messages where Cody provides multiple code suggestions, you can apply each in sequence to go from chat suggestions to written code.

### Context retrieval

When you start a new Cody chat, the chat input window opens with a default `@-mention` context chips for all the context it intends to use. This context is based on your current repository and current file (or a file selection if you have code highlighted).

![jb-context-retrieval](https://storage.googleapis.com/sourcegraph-assets/Docs/jb-context-retrieval-0824.jpg)

At any point in time, you can edit these context chips or remove them completely if you do not want to use these as context. Any chat without a context chip will instruct Cody to use no codebase context. However, you can always provide an alternate `@-mention` file or symbols to let Cody use it as a new source of context.

When you have both a repository and files @-mentioned, Cody will search the repository for context while prioritizing the mentioned files.

### Selecting Context with @-mentions

Cody's chat allows you to add files and symbols as context in your messages.

- Type `@-file` and then a filename to include a file as a context
- Type `@#` and then a symbol name to include the symbol's definition as context. Functions, methods, classes, types, etc., are all symbols

The `@-file` also supports line numbers to query the context of large files. You can add ranges of large files to your context by @-mentioning a large file and appending a number range to the filename, for example, `@filepath/filename:1-10`.

When you `@-mention` files to add to Cody’s context window, the file lookup takes `files.exclude`, `search.exclude`, and `.gitgnore` files into account. This makes the file search faster as a result up to 100ms.

Moreover, when you `@-mention` files, Cody will track the number of characters in those files against the context window limit of the selected chat model. As you `@-mention` multiple files, Cody will calculate how many tokens of the context window remain. When the remaining context window size becomes too small, you get **File too large** errors for further more `@-mention` files.

Cody defaults to showing @-mention context chips for all the context it intends to use. When you open a new chat, Cody will show context chips for your current repository and current file (or file selection if you have code highlighted).

### Rerun prompts with different context

If Cody's answer isn't helpful, you can try asking again with different context:

- **Public knowledge only**: Cody will not use your own code files as context; it’ll only use knowledge trained into the base model.
- **Current file only**: Re-run the prompt again using just the current file as context.
- **Add context**: Provides @-mention context options to improve the response by explicitly including files, symbols, remote repositories, or even web pages (by URL).

![jb-rerun-context](https://storage.googleapis.com/sourcegraph-assets/Docs/jb-rerun-context-0824.jpg)

## Context fetching mechanism

JetBrains users on the Free or Pro plan can leverage [local search](/cody/core-concepts/context#context-selection) as the primary context source for Cody chat. Local or remote embeddings will no longer be produced or used as a context source.

Enterprise users can leverage the full power of the Sourcegraph search engine as the primary context provider to Cody.

<Callout type="info"> Read more about [Context fetching mechanism](/cody/core-concepts/context/#context-fetching-mechanism) in detail.</Callout>

## Context scope

JetBrains users on the Free or Pro plan get single-repo support in chat and can use one repo for context fetching. Enterprise users get multi-repo support in chat and can explicitly specify **up to 10 additional repos** they would like Cody to use for context.

## Context Selection

Cody automatically understands the context of your codebase for all Cody Free, Pro, and Enterprise users based on the project opened in your workspace. Enterprise users can add up to **9 additional repos (10 total, including the default project)** to use as context. The multi-repo context for Enterprise is powered by Sourcegraph code search and allows Cody to use the selected codebase to answer your questions.

Moreover, Cody's chat allows you to add files as context in your messages. Type `@-file` in the Cody chat window and then a filename to include a file as context.

### Chat with multi-repo context

For Cody Free and Cody Pro users, if you delete all the context from the chat input, Cody will not use any local context. When this happens, Cody doesn't search your local project for context and sends your prompt to the selected LLM.

Cody Enterprise users can add remote repositories from your Sourcegraph instance. You can type the name of your repositories into this interface and select up to **9 additional repos (10 total, including the default project)**. Cody will then search against those repositories and retrieve relevant files to answer your chat prompts.

### Cody Context Filters

<Callout type="note">Context Filters is available for all Cody Enterprise users running Cody JetBrains extension version `>=6.0.0`.</Callout>

Admins on the Sourcegraph Enterprise instance can use the Cody Context Filters to determine which repositories Cody can use as the context in its requests to third-party LLMs. Inside your site configuration, you can define a set of `include` and `exclude` rules that will be used to filter the list of repositories Cody can access.

For repos mentioned in the `exclude` field, Cody's commands are disabled, and you cannot use them for context fetching. If you try running any of these, you'll be prompted with an error message. However, Cody chat will still work, and you can use it to ask questions.

[Read more about the Cody Context Filters here →](/cody/capabilities/ignore-context)

## Prompts and Commands

Cody with JetBrains offers quick, ready-to-use [prompts and commands](/cody/capabilities/commands) for common actions to write, describe, fix, and smell code. These allow you to run predefined actions with smart context-fetching anywhere in the editor. These allow you to run predefined actions with smart context-fetching anywhere in the editor, like:

- **Edit Code**: Makes inline code edits. You also get the option to select LLM for edit suggestions
- **Document Code**: Create inline documentation for your code
- **Generate Unit Test**: Creates inline unit tests for your code
- **Smell Code**: Finds code smells in your file
- **Explain Code**: Expains code in your file

![jetbrains-prompts-commands](https://storage.googleapis.com/sourcegraph-assets/Docs/jb-prompts-commands-0824.jpg)

Let's learn about how to use some of these commands:

### Inline code edits

You can make edits to your code directly in your file without opening the chat window. The **Edit Code** command makes direct code edits, refactors, or bug fixes.

You can run the inline edit command on a selected code snippet, an entire file, or to generate code on a new line. To do so, use the **Edit Code** command in the Cody sidebar or context menu, or the `Shift + Ctrl + Enter` shortcut. This opens a floating editor where you can describe the change you want to make.

Once you enter your prompt, Cody will perform inline edits that you can **Accept**, **Undo**, or **Show diff** for the change. You can also click **Edit & Retry** to iterate your prompt and get alternate suggestions.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/jb-code-edits-0824.mp4" type="video/mp4"/>
</video>

### Inline unit tests

The Generate Unit Test command uses the code edit functionality to create unit tests. To generate unit tests for your code, type `Shift + Ctrl + T` or click the **Generate Unit Test** command in the Cody sidebar or from the context menu.

When you run this command, it performs the following actions:

- Check if you’re using a test framework
- Check if you already have a test file created
- Insert new unit tests directly in the existing test file or create a new file if none exists

Here, you can **Accept**, **Undo**, or **Show diff** for the change.

### Inline code fix

Cody with JetBrains can also propose fixes and updates to errors in your code. The inline **Ask Cody to Fix** functionality alerts a user when it notices an issue and provides a workflow to suggest a fix, review the suggestion, and accept the change, all within the editor.

All you need to do is select and highlight the code line with the error and click the lightbulb icon. Then select **Ask Cody to Fix**. You can then view the diff and accept or undo the suggested change.

### Document your code

Like the Edit Code and Generate Unit Test commands, you can generate inline documentation for your code without opening the chat window. Doc command is available via hotkey, context menu, and Cody sidebar. Type `Shift + Ctrl + H`, and Cody will start generating documentation for your selected code snippet or the entire file.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/jb-document-code-0824.mp4" type="video/mp4"/>
</video>

## Autocomplete

Cody provides multi-line autocomplete as you type. Autocomplete suggestions appear as inlay suggestions and are enabled by default in your JetBrains IntelliJ editor. With this setting, there is a list of programming languages supported and enabled by default.

To manually configure the Autocomplete feature,

- Go to the **Cody Settings...** from the Cody icon in the sidebar
- Next, click the **Sourcegraph & Cody** dropdown and select **Cody**
- The **Autocomplete** settings will appear with the list of **Enabled Languages**

Autocomplete suggestions use the same color as inline parameter hints according to your configured editor theme. However, you can optionally enable the **Custom color for completions** checkbox to customize the color of your choice.

In addition, you can use the following keyboard shortcuts to interact with Cody's autocomplete suggestions:

- `Tab` to accept a suggestion
- `Alt + [` (Windows) or `Opt + [` (macOS) to cycle suggestions
- `Alt + \` (Windows) or `Opt + \` (macOS) to manually trigger autocomplete if no suggestions have been returned

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/jetbrains-cody-v6-autocomplete.mp4" type="video/mp4"/>
</video>

## Add or remove account

To add or remove an account you can do the following:

1. Open your IntelliJ settings by selecting **IntelliJ IDEA | Settings** on macOS or **File | Settings** on Windows and Linux from the main menu.
1. Get to the Cody Settings by navigating to `Tools -> Sourcegraph & Cody`
1. Under authentication see the accounts that are currently logged in
1. To remove, select your account and hit `-`. To add click `+` and choose the appropriate login method

## Change update channel for stable or nightly releases

Our nightly release channel gets updated much more frequently and might be helpful to verify bug fixes that will come in the next stable release.
To update your update channel you can do the following:

1. Open your IntelliJ settings by selecting **IntelliJ IDEA | Settings** on macOS or **File | Settings** on Windows and Linux from the main menu.
1. Get to the Cody Settings by navigating to `Tools -> Sourcegraph & Cody`
1. Under update channel select `Stable` or `Nightly`

## Find Cody features

Using the **Search Everywhere** option in JetBrains IDEs you can find and discover all Cody features and actions. Press `Shift` twice to open the `Search Everywhere` window. Then, type in the `Cody:` prefix to get a list of all supported Cody actions.

![serach-everywhere](https://storage.googleapis.com/sourcegraph-assets/Docs/search-everywhere-cody.png)
