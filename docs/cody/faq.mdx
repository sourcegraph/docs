# Cody FAQs

<p className="subtitle">
	Find answers to the most common questions about Cody.
</p>

## General

### Does Cody train on my code?

For Enterprise customers, Sourcegraph will not train on your company’s data. Our third-party Language Model (LLM) providers do not train on your specific codebase. Cody operates by following a specific process to generate answers to your queries:

-   **User query**: A user asks a question
-   **Code retrieval**: Sourcegraph, our underlying code intelligence platform, performs a search and code intelligence operation to retrieve code snippets relevant to the user's question. During this process, strict permissions are enforced to ensure that only code that the user has read permission for is retrieved
-   **Prompt to Language Model**: Sourcegraph sends a prompt, and the code snippets are retrieved to a Language Model (LLM). This prompt provides the context for the LLM to generate a meaningful response
-   **Response to user**: The response generated by the LLM is then sent back to Cody and presented to the user

This process ensures that Cody can provide helpful answers to your questions while respecting data privacy and security by not training on or retaining your specific code.

### Does Cody work with self-hosted Sourcegraph?

Yes, Cody is compatible with self-hosted Sourcegraph instances. However, there are a few considerations:

-   Cody operates by sending code snippets (up to 28 KB per request) to a third-party cloud service. By default, this service is Anthropic but can also be OpenAI
-   To use Cody effectively, your self-hosted Sourcegraph instance must have internet access for these interactions with external services

### Is there a public facing Cody API?

Currently, there is no public-facing Cody API available.

### Does Cody require Sourcegraph to function?

Yes, Cody relies on Sourcegraph for two essential functions:

-   It is used to retrieve context relevant to user queries
-   Sourcegraph acts as a proxy for the LLM provider to facilitate the interaction between Cody and the LLM

### What programming languages does Cody support?

Cody supports a wide range of programming languages, including:

-   JavaScript
-   TypeScript
-   PHP
-   Python
-   Java
-   C/C++
-   C#
-   Ruby
-   Go
-   SQL
-   Swift
-   Objective-C
-   Perl
-   Rust
-   Kotlin
-   Scala
-   Groovy
-   R
-   MATLAB
-   Dart
-   Lua
-   Julia
-   COBOL
-   Shell scripting languages (like Bash, PowerShell)

Cody's response quality on a programming language depends on many factors, including the underlying LLM being used. We monitor accuracy metrics across all languages and regularly make improvements.

### Can Cody answer non-programming questions?

Cody Chat is optimized for coding related use cases and can be used primarily for reviewing, analysis, testing, writing, and editing of software code. Use of Cody for any other purposes is against our [acceptable use policy](https://sourcegraph.com/terms/aup) and may result in your account being restricted.

## Embeddings

### Why were embeddings removed once my instance was upgraded to v5.3?

Cody leverages **Sourcegraph Search** as a primary context provider, which comes with the following benefits:

-   **More secure**: No code being sent to a third-party embedding API
-   **Easier to manage**: Less tech debt for embeddings setup and need for refreshes
-   **More repos**: Sourcegraph Search scales to larger repos and a greater number. Users on Enterprise instances will now be able to select multiple repos as context sources from within the IDE
-   **Equal, or better, quality**: Sourcegraph Search provides high-quality retrieval, as tested over the last ten years. When a customer sees degradation, we will be ready to respond quickly.

We leverage multiple retrieval mechanisms to give Cody the right context and will be constantly iterating to improve Cody's quality. The most important aspect is getting the files from the codebase, not the specific algorithm used to find those files.

### Why are embeddings no longer supported on Enterprise?

Cody does not support embeddings on Cody Enterprise because we have replaced them with Sourcegraph Search. There are two driving factors:

-   The need for a retrieval system that can scale across repos and to repos of greater size
-   A system that is secure and requires low maintenance on the part of users

Leveraging Sourcegraph Search allowed us to deliver these enhancements.

## LLM Data Sharing and Retention

### Is any of my data sent to DeepSeek?

Our autocomplete features uses the open source DeepSeek-Coder-V2 model, which is hosted by Fireworks.ai in a secure single-tenant environment located in the USA. No customer chat or autocomplete data - such as chat messages, or context such as code snippets or configuration - is stored by Fireworks.ai.

Sourcegraph does not use models hosted by DeepSeek (the company), and does not send any data to the same.

## Third party dependencies

### What is the default `sourcegraph` provider for completions?

The default provider for completions, specified as `"provider": "sourcegraph"` refers to the [Sourcegraph Model Provider (Cody Gateway)](/model-provider). The Sourcegraph Model Provider facilitates access to completions for Sourcegraph enterprise instances by leveraging third-party services such as Anthropic and OpenAI.

### What third-party cloud services does Cody depend on?

Cody relies on one primary third-party dependency, i.e., Anthropic's Claude API. Users can use this with the OpenAI API configuration.

It's worth noting that these dependencies remain consistent when utilizing the [default `sourcegraph` provider, Sourcegraph Model Provider (Cody Gateway)](/model-provider), which uses the same third-party providers.

### What is the retention policy for Anthropic and OpenAI?

Please refer to this [terms and conditions](https://about.sourcegraph.com/terms/cody-notice) for details regarding the retention policy for data managed by Anthropic and OpenAI.

### Can I use my own API keys?

Yes, BYOK (Bring Your Own Key) is fully supported in the Enterprise plan.

### Can I use Cody with my Cloud IDE?

Yes, Cody supports the following cloud development environments:

-   vscode.dev and GitHub Codespaces (install from the VS Code extension marketplace)
-   Any editor supporting the [Open VSX Registry](https://open-vsx.org/extension/sourcegraph/cody-ai), including [Gitpod](https://www.gitpod.io/blog/boosting-developer-productivity-unleashing-the-power-of-sourcegraph-cody-in-gitpod), Coder, and `code-server` (install from the [Open VSX Registry](https://open-vsx.org/extension/sourcegraph/cody-ai))

### Can I use my LLM of preference to chat with Cody on CLI?

Yes you can. In the CLI you can use the following command to get started. Please replace `$name_of_the_model` with the LLM model of your choice.

```shell
cody chat --model '$name_of_the_model' -m 'Hi Cody!'
```

For example, to use Claude 3.5 Sonnet, you'd pass the following command in your terminal, `cody chat --model 'claude-3.5-sonnet' -m 'Hi Cody!'

### Sign-in dialog gets stuck with Kaspersky Antivirus

**Problem:** When attempting to sign in, users may encounter a perpetual `"Signing in to Sourcegraph..."` dialog that never completes. This issue persists across different VS Code extension versions (e.g. 1.40-1.48) and browsers (Chrome, Edge, Firefox). In the browser console at `accounts.sourcegraph.com/sign-in`, you might see an error: `"Uncaught ApolloError: value.toString is not a function"`.

**Solution:** This issue is typically caused by Kaspersky Antivirus interfering with the authentication process. To resolve:

-   Locate the Kaspersky icon in your system tray
-   Right-click on the Kaspersky icon
-   Select "Stop Protection"
-   Right-click the icon again
-   Select "Exit"

<Callout type="warning">
	Once you are signed in make sure to re-enable protection.
</Callout>

## OpenAI o1

### What are OpenAI o1 best practices?

#### Context Management

-   Provide focused, relevant context
-   Use file references strategically
-   Keep initial requests concise

#### Model Selection

-   **Sonnet 3.5**: Better for tasks requiring longer outputs

#### Prompting Strategy

-   Be specific and direct
-   Include complete requirements upfront
-   Request brief responses when possible
-   Use step-by-step approach for complex tasks

#### Response Time

-   Start with smaller contexts
-   Consider breaking complex tasks into stages

#### Quality

-   Provide clear acceptance criteria
-   Include relevant context but avoid excess
-   Use specific examples when possible

### What are the known limitations?

#### Technical Constraints

-   45k input token limit
-   4k output token limit
-   No streaming responses for o1 series
-   Limited context window

## Sunsetting Cody Free, Pro, and Enterprise Starter plans

### What is the impact?

Starting July 23, 2025, Cody will no longer be available for Free, Pro and Enterprise Starter plans. Existing users will continue to have access until this date.

This change **will not impact Cody Enterprise customers**. They will continue to have access to Cody. We are fully committed and invested in Cody Enterprise and will continue to serve our customers.

### What does this mean if you are a Cody Free, Pro, Enterprise Starter, or Enterprise user?

Starting June 25, you cannot sign up for new Cody Free or Cody Pro accounts, and the new Enterprise Starter workspaces will not include Cody.

If you're a Cody Free user:

-   You will have access to Cody Free until July 23, 2025. After this, you'll no longer be able to use Cody.
-   Instead, you can sign up with Amp and receive **$10 in free credits** at [ampcode.com](http://ampcode.com/).

If you're a Cody Pro user:

-   You will have access to Cody Pro until July 23, 2025. After this, you'll no longer be able to use Cody.
-   You **will not be charged for Cody Pro** between now and July 23, 2025.
-   Cody Pro customers can sign up with Amp today at [ampcode.com](http://ampcode.com) and receive **$10 in free credits** **plus $30 additional free credits** as a thank you for using Cody Pro.

If you're on Enterprise Starter:

-   Your workspaces will have Cody access until \*July 23, 2025, after which Cody's access will be removed.
-   Your Enterprise Starter subscription remains fully supported for Code Search, with upcoming improvements like Deep Search.
-   Enterprise Starter customers can sign up with Amp today at [ampcode.com](http://ampcode.com) and receive **$10 in free credits** **plus $30 additional free credits** as a thank you for using Enterprise Starter.

If you're an Enterprise user:

-   **This change will not impact you**. We're fully committed to serving you.
-   You can continue to use Cody Enterprise as this remains fully supported and actively invested in.

### Why is this change being made?

AI is evolving rapidly, and so are developers' workflows. To stay focused and aligned with those needs, we're simplifying our product roadmap and offerings.

**Cody Enterprise will actively be supported, developed, and maintained**. It will continue to offer AI-powered development workflows for secure, collaborative, and large-scale teams.

But with AI now capable of handling more complex, agentic, and autonomous workflows, we've built [**Amp**](https://ampcode.com/) — our agentic, team-ready AI coding tool.

### Is there any replacement for Cody Free and Pro?

Yes, [**Amp**](https://ampcode.com/) is our new AI coding tool for agentic workflows and team collaboration.

It runs in VS Code with compatible forks like Cursor, Windsurf, and VSCodium and as a CLI. It's also multiplayer — you can share threads and collaborate with your team.

Amp is your way forward if you're using Cody Free or Pro. Sign up today for $10 in Amp credits if you're a Cody Free user and $40 in Amp credits if you're a Cody Pro user.

### How can I learn more about Amp?

We've built [Amp's Manual](https://ampcode.com/manual) to help you get started with Amp. In addition, if you need more help for this Cody > Amp transition please reach out to us in [Discord](https://discord.com/servers/sourcegraph-969688426372825169).
